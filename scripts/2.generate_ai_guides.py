import csv
import os
import json
import time
import logging
import glob
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from common import setup_logging, setup_gemini, clean_json_response, DATA_DIR, CONTENT_DIR, LOG_DIR

# --- ì„¤ì • ---
setup_logging("guide_gen.log")
model = setup_gemini()

INPUT_CSV = os.path.join(DATA_DIR, "guide_topics.csv")
OUTPUT_DIR = CONTENT_DIR
HISTORY_FILE = os.path.join(LOG_DIR, "guide_processed_history.txt")

LIMIT = 12        # í•œ ë²ˆ ì‹¤í–‰ ì‹œ ìƒì„±í•  ìµœëŒ€ ê°œìˆ˜
MAX_WORKERS = 3    # ë™ì‹œì— ì‘ì„±í•  ê°€ì´ë“œ ìˆ˜ (ê¸´ í…ìŠ¤íŠ¸ ìƒì„±ì´ë¯€ë¡œ 2~4 ê¶Œì¥)

THUMBNAILS = {
    "Cost": "https://images.unsplash.com/photo-1561414927-6d86591d0c4f?w=500",
    "Budget": "https://images.unsplash.com/photo-1561414927-6d86591d0c4f?w=500",
    "Selection": "https://images.unsplash.com/photo-1528164344705-47542687000d?w=500",
    "Visa": "https://images.unsplash.com/photo-1436491865332-7a61a109cc05?w=500",
    "Housing": "https://images.unsplash.com/photo-1522708323590-d24dbb6b0267?w=500",
    "Part-time": "https://images.unsplash.com/photo-1556740758-90de374c12ad?w=500",
    "Exam": "https://images.unsplash.com/photo-1434030216411-0b793f4b4173?w=500",
    "Preparation": "https://images.unsplash.com/photo-1501504905252-473c47e087f8?w=500",
    "Settlement": "https://images.unsplash.com/photo-1563986768609-322da13575f3?w=500",
    "Insurance": "https://images.unsplash.com/photo-1505751172876-fa1923c5c528?w=500",
    "Region": "https://images.unsplash.com/photo-1542051841857-5f90071e7989?w=500",
    "default": "https://images.unsplash.com/photo-1522202176988-66273c2fd55f?w=500"
}

def load_history():
    if not os.path.exists(HISTORY_FILE): return set()
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def append_history(slug):
    # ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œ íŒŒì¼ ì“°ê¸° ì‹œ ì•ˆì „ì„ ìœ„í•´ ê°„ë‹¨í•œ ì—ëŸ¬ ë°©ì§€
    with open(HISTORY_FILE, "a", encoding="utf-8") as f:
        f.write(f"{slug}\n")

def get_thumbnail(category):
    if not category: return THUMBNAILS["default"]
    for key, url in THUMBNAILS.items():
        if key in category: return url
    return THUMBNAILS["default"]

def generate_content(row):
    # ê¸´ ë¬¸ì¥ ìƒì„±ì´ë¯€ë¡œ íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ë¡œì§ ê°•í™”
    prompt = f"""
    You are an expert author who writes comprehensive guides for international students preparing to study in Japan.
    Write a long-form, detailed blog post in **ENGLISH** based on the topic below.
    The article must be well-structured, informative, and easy to read.
    
    **Total length must be between 7000 and 8000 characters.**
    
    ---
    Topic Title: {row['title']}
    Core Prompt: {row['prompt']}
    ---
    
    Guidelines: 
    - Use standard Markdown format.
    - Create 3-5 main sections with clear headings (##).
    - Use bullet points and lists where appropriate.
    - Include at least two Markdown tables for comparisons or data.
    - Maintain a friendly, encouraging, and professional tone in English.
    - Generate ONLY the Markdown body content (do not include frontmatter).
    """
    for i in range(3):
        try:
            response = model.generate_content(prompt)
            return clean_json_response(response.text)
        except Exception as e:
            if "429" in str(e): # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ëŒ€ê¸°
                time.sleep(15 * (i + 1))
            else:
                time.sleep(5)
    return None

def process_topic(row):
    """í•œ ê°œì˜ ì£¼ì œë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë‹¨ìœ„ ì‘ì—…"""
    slug = row['slug']
    filename = f"guide_{slug}.md"
    filepath = os.path.join(OUTPUT_DIR, filename)

    content_body = generate_content(row)
    
    if content_body:
        thumbnail_url = get_thumbnail(row['category'])
        frontmatter_data = {
            "layout": "guide", 
            "id": slug, 
            "title": row['title'],
            "category": row['category'], 
            "tags": [row['category']],
            "description": row['description'], 
            "thumbnail": thumbnail_url,
            "date": time.strftime("%Y-%m-%d")
        }
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("---\n")
            f.write(json.dumps(frontmatter_data, ensure_ascii=False, indent=2))
            f.write("\n---\n\n")
            f.write(content_body)
        
        append_history(slug)
        return f"âœ… Success: {filename}"
    else:
        return f"âŒ Failed: {slug}"

def main():
    if not os.path.exists(INPUT_CSV):
        print(f"âŒ CSV file not found: {INPUT_CSV}")
        return
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)

    with open(INPUT_CSV, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        all_topics = list(reader)

    processed_slugs = load_history()
    topics_to_process = [row for row in all_topics if row['slug'] not in processed_slugs]
    topics_to_process = topics_to_process[:LIMIT]
    
    print(f"ğŸš€ Total: {len(all_topics)} | Processed: {len(processed_slugs)} | Pending: {len(topics_to_process)}")
    print(f"âš¡ Running with {MAX_WORKERS} workers...")

    # --- ë©€í‹°ìŠ¤ë ˆë”© ì ìš© ---
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_topic = {executor.submit(process_topic, row): row for row in topics_to_process}
        
        for future in tqdm(as_completed(future_to_topic), total=len(topics_to_process)):
            row = future_to_topic[future]
            try:
                result = future.result()
                # ë¡œê¹… ì‹œìŠ¤í…œ í™œìš©
                logging.info(result)
            except Exception as e:
                logging.error(f"Error in {row['slug']}: {e}")

    print("\nğŸ‰ Generation finished.")

if __name__ == "__main__":
    main()