import json
import os
import time
import re
import frontmatter
from datetime import datetime
from common import setup_logging, setup_gemini, clean_json_response, DATA_DIR, CONTENT_DIR, LOG_DIR

# --- ì„¤ì • ---
setup_logging("auto_featured.log")
model = setup_gemini()

# í•™êµ ë°ì´í„° ê²½ë¡œ
SCHOOLS_JSON = os.path.join(os.path.dirname(DATA_DIR), "app", "static", "json", "schools_data.json")

# [ìë™ ìƒì„±í•  ì£¼ì œ ëª©ë¡]
# ì›í•˜ëŠ” ì£¼ì œë¥¼ ì—¬ê¸°ì— ê³„ì† ì¶”ê°€í•˜ë©´ AIê°€ ì•Œì•„ì„œ ê¸€ì„ ì”ë‹ˆë‹¤.
# [ìƒˆë¡œìš´ TOPICS ëª©ë¡]
TOPICS = [
    # 1. [ì·¨ì—…/ë¹„ì¦ˆë‹ˆìŠ¤] ë„ì¿„ì—ì„œ ì·¨ì—…í•˜ê¸° ê°€ì¥ ì¢‹ì€ í•™êµ
    {
        "slug": "best-business-schools-tokyo",
        "title": "Top 5 Schools in Tokyo for Finding a Job in Japan",
        "criteria": {
            "category": "school", 
            "tag": "business",  # ë¹„ì¦ˆë‹ˆìŠ¤/ì·¨ì—… íƒœê·¸
            "region": "æ±äº¬éƒ½"   # ë„ì¿„ ì§€ì—­
        },
        "count": 5,
        "thumbnail": "https://images.unsplash.com/photo-1486406146926-c627a92ad1ab?w=500" # ì˜¤í”¼ìŠ¤ ë¹Œë”© ì´ë¯¸ì§€
    },

    # 2. [ì§€ì—­/ë¬¸í™”] êµí† : ì¼ë³¸ì˜ ì „í†µ ì†ì—ì„œ ê³µë¶€í•˜ê¸°
    {
        "slug": "study-in-kyoto-top-picks",
        "title": "Study in Kyoto: Top 3 Schools in Japan's Cultural Capital",
        "criteria": {
            "category": "school", 
            "region": "äº¬éƒ½" # êµí†  ì§€ì—­ (ì£¼ì†Œì— 'äº¬éƒ½' í¬í•¨)
        },
        "count": 3,
        "thumbnail": "https://images.unsplash.com/photo-1493976040374-85c8e12f0c0e?w=500" # êµí†  ê±°ë¦¬ ì´ë¯¸ì§€
    },

    # 3. [ì „ê³µ/íŠ¹ê¸°] ì• ë‹ˆë©”ì´ì…˜ & ë””ìì¸ ìœ í•™ ì¶”ì²œ (í•™êµ/ëŒ€í•™ í˜¼í•© ê²€ìƒ‰)
    {
        "slug": "best-schools-for-design-arts",
        "title": "Best 4 Schools for Animation, Manga, and Design",
        "criteria": {
            "category": "school", # í˜¹ì€ universityë¡œ ë³€ê²½ ê°€ëŠ¥
            "tag": "Design"       # íŠ¹ì§•ì— Design, Art, Manga ë“±ì´ í¬í•¨ëœ í•™êµ
        },
        "count": 4,
        "thumbnail": "https://images.unsplash.com/photo-1613376023733-0a73315d9b06?w=500" # ë§Œí™”/ì• ë‹ˆë©”ì´ì…˜ ê´€ë ¨ ì´ë¯¸ì§€
    }
]

def load_data_and_build_index():
    """í•™êµ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ë§í¬ ìƒì„±ì„ ìœ„í•œ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•¨"""
    if not os.path.exists(SCHOOLS_JSON):
        print("âŒ schools_data.json not found. Run build_data.py first.")
        return [], []

    with open(SCHOOLS_JSON, 'r', encoding='utf-8') as f:
        data = json.load(f)
        schools = data.get('schools', [])

    # ë§í¬ ì¸ë±ìŠ¤ êµ¬ì¶• (ì´ë¦„ -> ID/Link)
    link_index = []
    for s in schools:
        name_en = s['basic_info'].get('name_en')
        if name_en and len(name_en) > 3:
            # ê´„í˜¸ ì œê±° ë“± ì •ì œ
            clean_name = re.sub(r'\s*\(.*?\)', '', name_en).strip()
            link_index.append({
                "name": clean_name,
                "link": s['link'], # /school/id
                "id": s['id']
            })
    
    # ê¸´ ì´ë¦„ë¶€í„° ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì •ë ¬ (ë¶€ë¶„ ì¼ì¹˜ ë°©ì§€)
    link_index.sort(key=lambda x: len(x['name']), reverse=True)
    
    return schools, link_index

def filter_schools(schools, criteria, limit):
    """ì¡°ê±´ì— ë§ëŠ” í•™êµ í•„í„°ë§"""
    candidates = []
    for s in schools:
        if s.get('category') != criteria['category']: continue
        
        full_text = str(s).lower()
        match = True
        
        if 'region' in criteria and criteria['region'] not in s['basic_info']['address']:
            match = False
        if 'tag' in criteria and criteria['tag'].lower() not in full_text:
            match = False
            
        if match:
            candidates.append(s)
            
    return candidates[:limit]

def generate_article_content(topic, selected_schools):
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ê¸°ì‚¬ ë³¸ë¬¸ ìƒì„±"""
    print(f"ğŸ¤– AI Writing: {topic['title']}...")
    
    schools_context = ""
    for s in selected_schools:
        name = s['basic_info']['name_en'] or s['basic_info']['name_ja']
        features = ", ".join(s.get('features', []))
        schools_context += f"- {name} (Features: {features})\n"

    prompt = f"""
    You are an expert editor for a 'Study in Japan' portal.
    Write a "Curated Ranking" article titled: "{topic['title']}".
    
    **Instructions:**
    1. Write a compelling introduction about this specific topic (approx 100 words).
    2. Create a numbered list (Ranking) for the selected schools below.
    3. For each school, write a dedicated section explaining WHY it is recommended. Focus on their unique strengths.
    4. **Language:** English Only.
    5. **Tone:** Professional, helpful, and encouraging.
    6. **Format:** Standard Markdown (Use ## for School Names).
    7. Do NOT include links manually. Just write the school names naturally.

    ---
    **Selected Schools:**
    {schools_context}
    ---
    
    Generate ONLY the Markdown body content.
    """
    
    try:
        response = model.generate_content(prompt)
        return clean_json_response(response.text)
    except Exception as e:
        print(f"âŒ Error generating {topic['slug']}: {e}")
        return None

def apply_auto_links(content, link_index):
    """ìƒì„±ëœ ë³¸ë¬¸ì— í•™êµ ë§í¬ ìë™ ì ìš©"""
    updated_content = content
    
    for item in link_index:
        name = item['name']
        link = item['link']
        
        # ì •ê·œì‹: ì´ë¯¸ ë§í¬ëœ í…ìŠ¤íŠ¸([]) ì œì™¸í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ íƒ€ê²ŸíŒ…
        pattern = re.compile(r'(?<!\[)\b' + re.escape(name) + r'\b(?!\])')
        
        if pattern.search(updated_content):
            # ë¬¸ì„œë‹¹ 'ì²« ë²ˆì§¸' ë“±ì¥ë§Œ ë§í¬ë¡œ ë³€ê²½
            replacement = f"[{name}]({link})"
            updated_content = pattern.sub(replacement, updated_content, count=1)
            
    return updated_content

def main():
    # 1. ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì¶•
    schools, link_index = load_data_and_build_index()
    if not schools: return

    print(f"ğŸ“š Loaded {len(schools)} schools & built link index.")

    # 2. ì£¼ì œë³„ ì²˜ë¦¬ ë£¨í”„
    for topic in TOPICS:
        # í•™êµ í•„í„°ë§
        selected_schools = filter_schools(schools, topic['criteria'], topic['count'])
        
        if not selected_schools:
            print(f"âš ï¸ Skipping {topic['title']} (No schools match criteria)")
            continue
            
        # AI ê¸°ì‚¬ ìƒì„±
        raw_content = generate_article_content(topic, selected_schools)
        
        if raw_content:
            # [í†µí•©] ìƒì„±ëœ ê¸€ì— ë°”ë¡œ ë§í¬ ì ìš©
            linked_content = apply_auto_links(raw_content, link_index)
            
            # íŒŒì¼ ì €ì¥
            filename = f"guide_{topic['slug']}.md"
            filepath = os.path.join(CONTENT_DIR, filename)
            
            frontmatter_data = {
                "layout": "guide",
                "id": topic['slug'],
                "title": topic['title'],
                "category": "Curated List",
                "is_featured": True, # ë©”ì¸ ìƒë‹¨ ë…¸ì¶œ
                "tags": ["Ranking", "Recommendation", topic['criteria'].get('tag', 'General')],
                "description": f"Our curated selection for {topic['title']}.",
                "thumbnail": topic['thumbnail'],
                "date": datetime.now().strftime("%Y-%m-%d")
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write("---\n")
                f.write(json.dumps(frontmatter_data, ensure_ascii=False, indent=2))
                f.write("\n---\n\n")
                f.write(linked_content) # ë§í¬ê°€ ì ìš©ëœ ë³¸ë¬¸ ì €ì¥
                
            print(f"âœ… Created & Linked: {filename}")
            
            # API ì¿¨íƒ€ì„ (ì•ˆì •ì„±)
            time.sleep(2)

if __name__ == "__main__":
    main()