import csv
import json
import os
import time
import requests
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from google.generativeai.types import GenerationConfig
from common import setup_logging, setup_gemini, clean_json_response, DATA_DIR, CONTENT_DIR, LOG_DIR

# --- ì„¤ì • ---
setup_logging("univ_gen.log")
model = setup_gemini()

LIMIT = 50
MAX_WORKERS = 5  # ë™ì‹œì— ì²˜ë¦¬í•  ê°œìˆ˜ (Gemini ìœ ë£Œ ê³„ì •ì€ 10~20, ë¬´ë£ŒëŠ” 2~5 ê¶Œì¥)
INPUT_CSV = os.path.join(DATA_DIR, "univ_list_100.csv")
OUTPUT_DIR = CONTENT_DIR
HISTORY_FILE = os.path.join(LOG_DIR, "univ_processed_history.txt")
GOOGLE_MAPS_API_KEY = os.getenv("GOOGLE_MAPS_API_KEY")

if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)

def load_history():
    if not os.path.exists(HISTORY_FILE): return set()
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def append_history(name):
    with open(HISTORY_FILE, "a", encoding="utf-8") as f:
        f.write(f"{name}\n")

def get_google_coordinates(address):
    if not address: return {"lat": 35.6812, "lng": 139.7671}
    base_url = "https://maps.googleapis.com/maps/api/geocode/json"
    params = {"address": address, "key": GOOGLE_MAPS_API_KEY, "language": "en"}
    try:
        res = requests.get(base_url, params=params, timeout=5) # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        data = res.json()
        if data['status'] == 'OK':
            loc = data['results'][0]['geometry']['location']
            return {"lat": loc['lat'], "lng": loc['lng']}
    except: pass
    return {"lat": 35.6812, "lng": 139.7671}

def get_university_info(name_ja, name_en):
    # ë©€í‹°ìŠ¤ë ˆë”© ì‹œ ì¶œë ¥ì´ ì„ì´ì§€ ì•Šë„ë¡ ê°„ë‹¨í•˜ê²Œ ì¶œë ¥
    prompt = f"""
    You are an expert consultant for international students planning to study in Japan.
    Analyze the university "{name_ja}" ({name_en}) and write an in-depth, comprehensive guide in **ENGLISH**.
    
    The output must be in Markdown format, follow the structure below precisely, and be **between 7000 and 8000 characters**.
    
    Required JSON Structure:
    {{
        "english_slug": "url-friendly-slug-in-english",
        "basic_info": {{
            "name_ja": "{name_ja}",
            "name_en": "{name_en}",
            "address": "Official address in English",
            "capacity": null
        }},
        "stats": {{
            "international_students": 123,
            "acceptance_rate": "Estimated % string"
        }},
        "tuition": {{
            "admission_fee": 123456,
            "yearly_tuition": 123456
        }},
        "faculties": ["List", "of", "faculties"],
        "features": ["Key Feature 1", "Key Feature 2"],
        "description": "## ğŸ« University Overview\\n...long text..."
    }}
    """
    for i in range(3):
        try:
            res = model.generate_content(
                prompt, generation_config=GenerationConfig(response_mime_type="application/json")
            )
            return json.loads(clean_json_response(res.text))
        except Exception as e:
            # 429 Error (Rate Limit) ë°œìƒ ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
            if "429" in str(e):
                time.sleep(10 * (i + 1))
            else:
                time.sleep(2)
    return None

def process_university(univ):
    """í•œ ëŒ€í•™êµë¥¼ ì²˜ë¦¬í•˜ëŠ” ë…ë¦½ì ì¸ ì‘ì—… ë‹¨ìœ„"""
    name_ja = univ['name_ja']
    name_en = univ['name_en']
    
    data = get_university_info(name_ja, name_en)
    if not data:
        return f"âŒ Failed: {name_ja}"

    addr = data['basic_info'].get('address')
    coords = get_google_coordinates(addr)
    
    raw_slug = data.get('english_slug', name_en.replace(" ", "-").lower())
    slug = f"univ_{raw_slug}" if not raw_slug.startswith("univ_") else raw_slug
    
    frontmatter_data = {
        "layout": "school", 
        "id": slug, 
        "title": data['basic_info']['name_en'],
        "category": "university",
        "tags": data.get('features', []), 
        "thumbnail": "/static/img/pin-univ.png", 
        "location": coords,
        "basic_info": data['basic_info'], 
        "stats": data['stats'], 
        "tuition": data['tuition'],
        "faculties": data.get('faculties', []), 
        "features": data.get('features', [])
    }

    filepath = os.path.join(OUTPUT_DIR, f"{slug}.md")
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write("---\n")
        f.write(json.dumps(frontmatter_data, ensure_ascii=False, indent=2))
        f.write("\n---\n\n")
        f.write(data.get('description', 'No content available.'))
    
    append_history(name_ja)
    return f"âœ… Saved: {slug}.md"

def main():
    if not os.path.exists(INPUT_CSV):
        print(f"âŒ {INPUT_CSV} file not found.")
        return

    processed_list = load_history()
    univ_list = []
    with open(INPUT_CSV, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row['name_ja'] not in processed_list:
                univ_list.append(row)
            
    univ_list = univ_list[:LIMIT] # ì²˜ë¦¬í•  ê°œìˆ˜ ì œí•œ
    print(f"ğŸš€ Total Universities to process: {len(univ_list)} | Workers: {MAX_WORKERS}")

    # --- ë©€í‹°ìŠ¤ë ˆë”© ì²˜ë¦¬ ë¶€ë¶„ ---
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # ì‘ì—… ë“±ë¡
        future_to_univ = {executor.submit(process_university, univ): univ for univ in univ_list}
        
        # tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ
        for future in tqdm(as_completed(future_to_univ), total=len(univ_list)):
            univ = future_to_univ[future]
            try:
                result = future.result()
                # print(result) # í•„ìš”ì‹œ ê²°ê³¼ ì¶œë ¥
            except Exception as e:
                print(f"âš ï¸ {univ['name_ja']} generated an exception: {e}")

if __name__ == "__main__":
    main()